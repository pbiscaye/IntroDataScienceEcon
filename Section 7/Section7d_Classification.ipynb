{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7. Classification\n",
    "\n",
    "#### Instructor: Pierre Biscaye\n",
    "\n",
    "The content of this notebook draws on material from UC Berkeley D-Lab's Python Machine Learning [course](https://github.com/dlab-berkeley/Python-Machine-Learning).\n",
    "\n",
    "A common task in computational research is to **classify** an object into a set of possible categories based on a set of features. In supervised machine learning, we can give an algorithm a dataset of training examples that say \"here are specific features, and this is the target class it belongs to\". With enough training examples, a model can be built that recognizes important features in determining an object's class. This model can then be used to predict the class of an object given its known features.\n",
    "\n",
    "### Sections\n",
    "1. Simple classification\n",
    "2. Logistic regression\n",
    "3. More model evaluation\n",
    "4. Decision trees\n",
    "5. Support vector machines (SVMs)\n",
    "\n",
    "First let's import the main packages that we need for this notebook. We'll import some additional packages for other classification models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penguin Data\n",
    "\n",
    "Let's say that we are studying penguins in Antartica. We have body measurements and location data for a set of penguins of three different species: Adelie, Chinstrap, and Gentoo. We are interested in being able to differentiate between these three species based on their characteristics. First, let's take a look at our data set, loading what we preprocessed in the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/penguins_X_train.csv')\n",
    "X_test = pd.read_csv('Data/penguins_X_test.csv')\n",
    "y_train = pd.read_csv('Data/penguins_y_train.csv')\n",
    "y_test = pd.read_csv('Data/penguins_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with just two penguin species: Adelie and Gentoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[y_train['species'].isin(['Adelie','Gentoo'])].reset_index()\n",
    "X_test = X_test[y_test['species'].isin(['Adelie','Gentoo'])].reset_index()\n",
    "y_train = y_train[y_train['species'].isin(['Adelie','Gentoo'])].reset_index()\n",
    "y_test = y_test[y_test['species'].isin(['Adelie','Gentoo'])].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple classification\n",
    "\n",
    "Let's say that we wanted to assign a species to each unknown measured penguin. One way to do this is to assign all observations to the majority class. The code below shows the proportion of each species in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts('species')/sum(y_train.value_counts('species'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** If we want to maximize accuracy, which species label would we assign to all observations? \n",
    "\n",
    "This level of accuracy, called 'null accuracy' is our **baseline model**, and is the number that we will try to improve on with classification.\n",
    "\n",
    "Let's get to know our dataset by conducting some exploratory data analysis. We'll be using some rudimentary data analysis to see there's a relationship between the independent variables across species.\n",
    "\n",
    "Let's say that we decide that body mass might be a good way to differentiate between Adelie and Gentoo penguins. We can look at a plot of the histogram to see how the distribution of this variable changes between species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.histplot(data=X_train,\n",
    "                x = 'body_mass_g',\n",
    "                hue = y_train['species'],kde=True,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Where would you place a boundary line to minimize the overlap in the distribution? \n",
    "\n",
    "Now let's apply this same decision boundary to the test data. \n",
    "\n",
    "**Question:** Is this still the best boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=X_test,\n",
    "                x = 'body_mass_g',\n",
    "                hue = y_test['species'],kde=True,bins=20)\n",
    "#plt.axvline(.28,color= 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic goal of classification. Based on your boundary criteria, you could **classify** all of the penguins. However there would be some error involved.\n",
    "\n",
    "We can be more confident in our classification at the far ends of the distribution, and less confident where the distributions overlap. \n",
    "\n",
    "Suppose the training data had suggested an optimal threshold of 0.28 of normalized body mass. Let's calculate the accuracy of this decision model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Copy X_test so we can create new columns\n",
    "prediction_df = X_test.copy()\n",
    "\n",
    "# 2. Create a 'prediction' column\n",
    "prediction_df['prediction'] = np.where(\n",
    "    prediction_df['body_mass_g'] < 0.28,  # condition\n",
    "    'Adelie',                             # if True\n",
    "    'Gentoo'                              # if False\n",
    ")\n",
    "\n",
    "# 3. Add the true species from y_test\n",
    "prediction_df['species'] = y_test['species'].values\n",
    "\n",
    "# 4. Compare 'prediction' to 'species'\n",
    "prediction_df['correct'] = prediction_df['prediction'] == prediction_df['species']\n",
    "\n",
    "# View the resulting DataFrame\n",
    "prediction_df['correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much better is this approach to majority class classification? This is also know as baseline accuracy, as we'll discuss later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of majority class classification\n",
    "y_test.value_counts('species')/sum(y_test.value_counts('species'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly body mass is highly predictive of species. Now let's figure out how to separate out these groups mathematically to see if we can achieve even better performance. \n",
    "\n",
    "For this, we will start by using an algorithm called Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "\n",
    "Logistic regression is a supervised classification algorithm that is used to predict a binary outcome. Similar to linear regression, this model uses coefficients or betas to make its predictions. However unlike a linear regression, its predictions range from 0 to 1, where 0 and 1 stand for 'confidently class A and B' respectively. Predictions in the middle of this range show less confidence in the prediction.\n",
    "\n",
    "The function for the logistic regression is:\n",
    "$$ p(x) = \\frac{1}{1 + e^{(-\\beta_0+\\beta_1x_1...)}}$$\n",
    "\n",
    "where $\\beta$ are the learned parameters and $x$ are the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Logistic Regression\n",
    "\n",
    "Logistic regression uses the same general steps as many other `sklearn` algorithms:\n",
    "1. Initialize Model\n",
    "2. Fit model on training data\n",
    "3. Evaluate on training and testing datasets\n",
    "\n",
    "Let's first train a univariate logistic regression model on the variable `body_mass_g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variety of parameters may be specified, but none are required\n",
    "?LogisticRegression.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Initialize Model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#2) Fit model\n",
    "# Note that the X argument must be a 2D array; with a univariate model we must reshape the data\n",
    "# Try running the below without .values.reshape(-1, 1) to see the error it returns\n",
    "lr.fit(X_train['body_mass_g'].values.reshape(-1, 1), y_train['species'])\n",
    "\n",
    "#3) Evaluate \n",
    "# The model will assign predicted species based on whether the estimated probability is closer to 0 or to 1\n",
    "train_score = lr.score(X_train['body_mass_g'].values.reshape(-1, 1), y_train['species'])\n",
    "test_score = lr.score(X_test['body_mass_g'].values.reshape(-1, 1), y_test['species'])\n",
    "\n",
    "print(\"Training score:\", round(train_score,3), \"Testing score:\", round(test_score,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well did the model do compared to the two simple classification approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Logistic Regression\n",
    "\n",
    "The univariate logistic regression did a pretty good job at classifying the penguins. However, we have more than just body mass help predict species. \n",
    "\n",
    "For example, let's look at the combination of culmen depth and body mass in our data by using a scatterplot. Does adding in culmen depth help to further distinguish the species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.scatterplot(data=X_train,\n",
    "                x = 'culmen_depth_mm',\n",
    "                y = 'body_mass_g',\n",
    "                hue = y_train['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two dimensional space, the intuition is that we want to draw a line that best separates the classes. \n",
    "\n",
    "**Question:** Is it possible to draw a line that completely separates the groups? If it is, this is a **linearly seperable** problem\n",
    "\n",
    "Let's retrain the logistic model with two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train[['body_mass_g','culmen_depth_mm']], y_train['species'])\n",
    "\n",
    "train_score = lr.score(X_train[['body_mass_g','culmen_depth_mm']], y_train['species'])\n",
    "test_score = lr.score(X_test[['body_mass_g','culmen_depth_mm']], y_test['species'])\n",
    "\n",
    "print(\"Training score = {}, testing score = {}\".format(round(train_score,3), round(test_score,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this doesn't happen often in real life, we got a perfect score! We could add more features to the model, but there isn't a need since our model is already behaving perfectly. Now let's take a look at the coefficients of the model. We reference the `lr.coef_` attribute to see the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(index=['body_mass_g','culmen_depth_mm'], data=lr.coef_[0])\n",
    "\n",
    "coef.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you think the *magnitude* and *sign* of the coefficients means about how these variables are related to each category?\n",
    "**Hint:** Refer back to the scatter plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model evaluation\n",
    "\n",
    "We've covered accuracy already but there are many other ways to evaluate the performance of a classification model.\n",
    "\n",
    "In a binary classification task, there are four major types of predictions:\n",
    "\n",
    "[Confusion Matrix (Wikipedia)](https://en.wikipedia.org/wiki/Confusion_matrix): \n",
    "- true positive (TP): A test result that correctly indicates the presence of a condition or characteristic\n",
    "- true negative (TN): A test result that correctly indicates the absence of a condition or characteristic\n",
    "- false positive (FP): A test result which wrongly indicates that a particular condition or attribute is present\n",
    "- false negative (FN): A test result which wrongly indicates that a particular condition or attribute is absent\n",
    "\n",
    "Accuracy, which is the most common metric used with classification can be characterized as:\n",
    "\n",
    "$$ Accuracy= \\frac{\\sum{\\text{True Positives}}+\\sum{\\text{True Negatives}}}{\\sum{\\text{Total Population}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the prediction measures above to create three helpful metrics for evaluating classification: **precision**, **recall**, and **specificity**. \n",
    "\n",
    "1. **Precision**:\n",
    "$$\\frac{\\sum{\\text{True Positives}}}{\\sum{\\text{Predicted Positives}}}$$\n",
    "2. **Recall** (or **Sensitivity**): \n",
    "$$\\frac{\\sum{\\text{True Positives}}}{\\sum{\\text{Condition Positives}}}$$ \n",
    "3. **Specificity** (like recall for negative examples): \n",
    "$$\\frac{\\sum{\\text{True Negatives}}}{\\sum{\\text{Condition Negatives}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a confusion matrix for the univariate logistic model and derive the recall and precision scores.\n",
    "\n",
    "First we will retrain the model and make predictions on the test set.\n",
    "\n",
    "Then we will use the `confusion_matrix()` function from `sklearn` to generate the confusion matrix.\n",
    "\n",
    "Then we can calculate recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train['body_mass_g'].values.reshape(-1, 1), y_train['species'])\n",
    "preds = lr.predict(X_test[['body_mass_g']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass y_test and preds into confusion_matrix\n",
    "confusion_matrix(y_test['species'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows indicate predictions being positive (top) or negative (bottom), and the columns indicate the truth being positive (left) or negative (right).\n",
    "\n",
    "We can therefore read this as:\n",
    "- TP: 36\n",
    "- FP: 1\n",
    "- TN: 24\n",
    "- FN: 6\n",
    "\n",
    "What is the precision and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision is {}'.format(round(36/(36+1),3)))\n",
    "print('recall/sensitivity is {}'.format(round(36/(36+6),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your task, other metrics than accuracy might be more beneficial to understanding your model's performance. At the very least, examining the confusion matrix is a great way to get a better sense of how your model is performing across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Trees\n",
    "\n",
    "Let's now include all three species of penguin that we want to differentiate between. We will need to use other models that can handle two or more classes for classification. \n",
    "\n",
    "One such example is the Decision Tree Classifier (there is also a Decision Tree Regressor). In terms of logic, this process works like a flow chart. In the flow chart below the the features are information about how a lamp doesn't work. The classes (that we want to predict) are the actions that are taken to make the lamp work, based on the features.\n",
    "\n",
    "![Alt](https://upload.wikimedia.org/wikipedia/commons/9/91/LampFlowchart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the ultimate goal of classification remains the same, machine learning algorithms vary widely in terms of *how* they go about this task. The neat thing about `sklearn` is that many algorithms use the same syntax, which makes comparing their performance on a task fairly straightforward. However, each model will have different underlying parameters and methods to identify the optimal split. When you are using a new model it is helpful to read up on how the model works. \n",
    "\n",
    "The documentation is a great way to do that. For example, you can read the [documentation](https://scikit-learn.org/stable/modules/tree.html#tree) for the Decision Tree algorithm and to get answers to the following questions:\n",
    "\n",
    "1) What are some advantages and disadvantages of the Decision Tree?\n",
    "2) What measures do Decision Trees use to determine optimal split?\n",
    "3) How do you import the Decision Tree from sklearn?\n",
    "\n",
    "**Decision Trees** are a classification/regression supervised learning algorithm that uses a series of splits to make its predictions.\n",
    "\n",
    "Decision Trees learn from the data by picking the feature-threshold that maximizes the information gain of the target variable. In other words it chooses a splitting point that produces the most imbalanced/pure proportions in the target variable. The goal of the model is to keep splitting until all the data in a terminal node or leaf are exclusively one class. A terminal node--where no further splitting occurs--is called a **leaf** in reference to the whole architecture being called a tree.\n",
    "\n",
    "The model iterates through a set of values for each feature and then calculates statistics for each split (see 'criterion' below) and chooses a designated split based on the best statistic value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "There are many [parameters](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for the Decision Tree Classifier. A few relevant to this notebook are described here:\n",
    "\n",
    "**criterion**: The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity (default) and \"log-loss\" and “entropy” for the Shannon information gain.\n",
    "\n",
    "**splitter**: The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split (default) and “random” to choose the best random split.\n",
    "\n",
    "**max_depth**: The maximum depth of the tree, with default=None. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "**min_samples_split**: The minimum number of samples needed to split an internal node (default 2).\n",
    "\n",
    "**min_samples_leaf**: The minimum number of samples required to be at a leaf node (default 1). A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "**max_features**: The number of features to consider when looking for the best split (default is no maximum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a decision tree model on the penguins data set. We are going to start with a default DT model, meaning we're not going to pass in any parameters of our own. Like we did before, we are going to fit a model and then evaluate it on the training and testing datasets. Let's start with a single x-feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Reload the traning and test data with all species\n",
    "X_train = pd.read_csv('Data/penguins_X_train.csv')\n",
    "X_test = pd.read_csv('Data/penguins_X_test.csv')\n",
    "y_train = pd.read_csv('Data/penguins_y_train.csv')\n",
    "y_test = pd.read_csv('Data/penguins_y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit model on the dataset\n",
    "dt.fit(X_train[['body_mass_g']], y_train['species'])\n",
    "\n",
    "# Derive the training accuracy score\n",
    "dt.score(X_train[['body_mass_g']], y_train['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "dt.score(X_test[['body_mass_g']], y_test['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Our testing score is considerably lower. When the testing score is lower than the training score, what does that mean?\n",
    "\n",
    "We can take advantage of some of the parameters of the decision tree in order to help prevent overfitting of the model. Let's try a model in which we impose some constraints on the tree.\n",
    "\n",
    "**Question:** From the documentation, what is one parameter that might help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "# Fit \n",
    "dt.fit(X_train[['body_mass_g']], y_train['species'])\n",
    "\n",
    "# Evaluate\n",
    "train_score = dt.score(X_train[['body_mass_g']], y_train['species'])\n",
    "test_score = dt.score(X_test[['body_mass_g']], y_test['species'])\n",
    "\n",
    "print(\"Our training score is {} and our testing score is {}\".format(round(train_score,3), round(test_score,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gap between the two scores is considerably lower. Arguably we don't have an overfit model anymore. However, we could likely improve on the accuracy of this model by including more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Visualization\n",
    "\n",
    "One big advantage of the Decision Tree is that it can be visualized no matter how many features were involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plot_tree(dt, feature_names=['body_mass_g'], class_names=[\"Adelie\", \"Chinstrap\",\"Gentoo\"], \n",
    "          filled = True, proportion=True, fontsize=18\n",
    "         );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret this?\n",
    "\n",
    "The root node states\n",
    "* `body_mass_g <= 0.163`: this is the criteria for splitting the decision tree.\n",
    "* `gini = 0.639`: this is a measure of how 'impure' or heterogeneous the node is with respect to the target classes. It is calculated as $G(n)=\\sum_{i=1}^K p_i (1-p_i)$.\n",
    "* `samples = 100.0\\%`: all samples are included in this node.\n",
    "* `value=[0.438, 0.205, 0.357]`: these are the shares of the samples in the three classes of species. \n",
    "* `class = Adelie`: the predicted class at this node in the decision tree.\n",
    "\n",
    "**Question** Which leaf is the most 'pure'? Which is the most 'impure'?\n",
    "\n",
    "**Question** No leaves terminate in classifying any penguins as Chinstrap. Which current leaf would be most likely to result in such a classification if it was split once more?\n",
    "\n",
    "**Question** Using the tree, how would we make predictions about the following penguins? How accurate are these predictions likely to be?\n",
    "* Penguin A: Body Mass of .5\n",
    "* Penguin B: Body Mass of 0\n",
    "\n",
    "In the practice notebook, you can work on estimating a decision tree with more features to see how the performance improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning a Decision Tree\n",
    "\n",
    "As with all prediction algorithms, we want to avoid overfitting. **Pruning** is a technique for reducing decision tree overfitting by simplifying the tree structure. In practice, pringing means removing subtrees or leaves that add little predicting power. Pruning a \"fully-grown\" tree model can help strike a balance between underfitting (too simple) and overfitting (too complex).\n",
    "\n",
    "**Pre-pruning** can be accomplished by careful selection of hyperparameters. This prevents a tree from \"over-growing\" as it is estimated. The arguments `max_depth` and `min_samples_leaf` are examples of parameters that prevent a tree from going too deep (having too many splits) and from splitting the sample into leaves with very small samples.\n",
    "\n",
    "**Post-pruning** involves predicting a complete tree with minimal pruning, estimating complexity of the whole tree and possible pruned sub-trees, and assigning a complexity penalty that helps target which sub-trees to prune. This is accomplished using `DecisionTreeClassifier(ccp_alpha=...)`, where `ccp_alpha` is the penalty parameter you specify, with a higher alpha imposes a greater complexity penalty. \n",
    "\n",
    "How to choose an appropriate alpha? You first estimate the Decision Tree Classifier without specifying `ccp_alpha`, and fit it to the training data. Then, pass `cost_complexity_pruning_path` on the resulting tree. You can then retrieve a range of alpha values you can iterate over to select one that maximizes validation performance.\n",
    "\n",
    "I invite you to explore this tool in the practice notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification with SVM\n",
    "\n",
    "Now let's try another new model. The [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html#classification) is another class of machine learning algorithm that is used for classification, regression, and outlier detection.\n",
    "\n",
    "For binary classification, SVMs aim to find the **hyperplane** that best separates two classes in a feature space by maximizing the margin, i.e., the distance between the hyperplane and the nearest data points from both classes (called support vectors).\n",
    "\n",
    "**Question** How does SVM fit in with the **linearly separable** problem identified in the scatter plots in the first part of this notebook?\n",
    "\n",
    "For multi-class problems, SVMs rely on decomposition strategies to reduce the problem into multiple binary classification tasks. The most common methods are:\n",
    "1. One-vs-One (OvO) Strategy: Create an SVM classifier for every pair of classes. Each classifier distinguishes between a pair of classes (e.g., class 1 vs. class 2, class 1 vs. class 3, etc.). For prediction of a new input, each binary classifier votes for one of its two classes. The class with the most votes across all classifiers is assigned as the prediction.\n",
    "2. One-vs-Rest (OvR) Strategy: Train an SVM classifier for each class. Each classifier distinguishes one class from all others (e.g., class 1 vs. the rest, class 2 vs. the rest, etc.). For prediction of a new input, it computes the decision function value for each classifier, and assign the class with the highest decision score.\n",
    "3. Direct Multi-Class SVM (Single Optimization): Solve a single optimization problem that incorporates constraints for all classes simultaneously. This is less commonly used due to computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have three penguin classes, it is a multi-class problem. The default approach in the `SVC` function for this prediction problem is OvR.\n",
    "\n",
    "We will choose two features of the data set to train our model on. Then, using the documentation for the support vector machine, we will:\n",
    "- Initialize the model\n",
    "- Fit it to the training data\n",
    "- Evaluate the model on both the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "?SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired features and target variable\n",
    "X_train_subset = X_train[['body_mass_g','culmen_depth_mm']]\n",
    "X_test_subset = X_test[['body_mass_g','culmen_depth_mm']]\n",
    "y_train_subset = y_train['species']\n",
    "y_test_subset = y_test['species']\n",
    "\n",
    "##1) Initialize SVM\n",
    "model = SVC()\n",
    "##2) Train SVM on Training data \n",
    "model.fit(X_train_subset,y_train_subset)\n",
    "##3) Evaluate SVM on Training and Test Data\n",
    "print('Training score: {}'.format(model.score(X_train_subset,y_train_subset)))\n",
    "print('Test score: {}'.format(model.score(X_test_subset,y_test_subset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model underfit? Is it overfit?\n",
    "\n",
    "How does it change with the addition of some additional features? Let's include the island data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired features and target variable\n",
    "X_train_subset = X_train[['body_mass_g','culmen_depth_mm','Dream','Torgersen']]\n",
    "X_test_subset = X_test[['body_mass_g','culmen_depth_mm','Dream','Torgersen']]\n",
    "y_train_subset = y_train['species']\n",
    "y_test_subset = y_test['species']\n",
    "\n",
    "##1) Initialize SVM\n",
    "model = SVC()\n",
    "##2) Train SVM on Training data \n",
    "model.fit(X_train_subset,y_train_subset)\n",
    "##3) Evaluate SVM on Training and Test Data\n",
    "print('Training score: {}'.format(model.score(X_train_subset,y_train_subset)))\n",
    "print('Test score: {}'.format(model.score(X_test_subset,y_test_subset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you conclude?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
