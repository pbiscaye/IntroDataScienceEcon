{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Raster Data\n",
    "\n",
    "#### Instructor: Pierre Biscaye\n",
    "\n",
    "The content of this notebook draws on material from UC Berkeley's Spatial Data Analysis [course](https://docs.google.com/document/d/1oC10pjyeBQTenQazCpaB8Lx1b5PC1SR3WFiPgCtXqcs/edit?tab=t.0) notes by [Jaecheol Lee](https://sites.google.com/view/jaecheollee).\n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Learn how to load and view raster data\n",
    "* Understand masking of spatial objects\n",
    "* Learn how to work with multidimensional raster data\n",
    "* Practice basic map algebra\n",
    "* Practice visualizing dynamic spatial data\n",
    "  \n",
    "### Sections\n",
    "1. Loading and mapping rasters using rasterio\n",
    "2. Masking and transforming spatial data\n",
    "3. Working with multidimensional rasters using xarray\n",
    "\n",
    "### Required Data\n",
    "* GPW.tif\n",
    "* gadm41_FRA_0.shp\n",
    "* gadm41_FRA_1.shp\n",
    "* AustraliaRainfall.nc\n",
    "\n",
    "### Required Packages\n",
    "* pickle\n",
    "* numpy\n",
    "* scipy\n",
    "* geopandas\n",
    "* matplotlib\n",
    "* rasterio\n",
    "* shapely\n",
    "* affine\n",
    "* xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading modules\n",
    "\n",
    "In this notebook we will be working with a new library `rasterio` that helps work with raster spatial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modules\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import rasterio.mask\n",
    "import rasterio.warp\n",
    "import rasterio.windows\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from shapely.geometry import (Point, LinearRing,\n",
    "                              Polygon, MultiPolygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and mapping rasters\n",
    "\n",
    "#### What is a raster?\n",
    "\n",
    "**Raster files** are images built from pixels â€” tiny color squares that, in great quantity, can form highly detailed images such as photographs. The more pixels an image has for a fixed area, the higher quality it will be, and vice versa.\n",
    "\n",
    "Raster files can include many different extensions but all include the same basic type of information.\n",
    "\n",
    "When a raster is a spatial object we can map the locations of the pixels in the image to locations on a map or grid, and use the information in each pixel (which may have several layers) to plot spatial information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Image/raster_vector.jpg\" width = \"500\">\n",
    "\n",
    "[Source: tellyourtale.com](https://tellyourtale.com/graphic-design/which-graphic-file-format-is-best-vector-and-raster-images/)\n",
    "\n",
    "<img src=\"Image/smile.png\" width = \"350\">\n",
    "\n",
    "[Source: Wikipedia](https://en.wikipedia.org/wiki/Raster_graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIFF and GeoTIFF files\n",
    "\n",
    "Two of the most common types of raster files are:\n",
    "* TIFF: Tagged Image File Format for storing raster graphics images.\n",
    "* GeoTIFF: TIFF file with georeferencing information embedded.\n",
    "\n",
    "Most `.tif` files we use in spatial analysis are GeoTIFF files. You can view them as a simple image (as with non-spatial TIFFs), but they embed scientific datasets. When you open a `.tif` in a standard image viewer, it might looks like a dark or grey mess. That is because image viewers are not built to interpret the content of these files, with the exception of the most simple.\n",
    "\n",
    "You can think of a GeoTIFF file as a collection of actual rasters (we will later deal with them as `numpy.ndarray`) and a collection of metadata that contains georeferencing information. The rasters hold different values for every pixel in the grid. The separate rasters are referred to as **bands**. A given GeoTIFF can have dozens of these, whereas a standard photo only has 3 (RGB). The potential **metadata** information includes map projection, coordinate systems, pixel size, and everything else necessary to establish the exact spatial reference for the file. \n",
    "\n",
    "GeoTIFFs have advantages over other image formats (like JPEG) such as lossless compression and including transparent \"NoData\" values.\n",
    "\n",
    "In this notebook we will be using data from the [Gridded Population of the World data set](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-rev11) produced by a team at Columbia University. We'll be using the version provided at a 15 arcminute or a 0.25 degree resolution (about 30km). Much higher resolution versions are available, but this low-resolution version will make computation much faster for training purposes. This version of the dataset describes the total number of individuals that are estimated to have lived in each grid cell in the year 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `rasterio` to load a raster and exploring metadata\n",
    "\n",
    "We now start exploring how to use `rasterio` to read existing GeoTIFF files and perform some useful operations on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rasterio.open('Data/GPW.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the metadata (data that provides information about other data) of the GeoTIFF file first.\n",
    "\n",
    "We want to know how many layers (bands) there are in the file. A band is like a layer, or a channel. An RGB image, for example, has three channels/bands/layers. Each band shares the same georeferencing information with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or alternatively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see `(1,)` that means that there is only one band in the raster. `rasterio` starts counting from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the coordinate reference system (CRS) by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is EPSG 4326/WGS84: World Geodetic System 1984, commonly used in GPS. This maps a point on earth to a set of longitude, latitude coordinate (notice that epsg 4326 uses the order [lon, lat]). \n",
    "\n",
    "Next, we can check how many grid cells there are by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the sequence of height and width here!\n",
    "# This is a rasterio convention, which can be different from other packages\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.height, dataset.width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the bounds of the GeoTIFF: the coordinates of the pixels on the corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also view a metadata summary\n",
    "dataset.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'nodata'` refers to a special value that rasterio uses to store NaN values. In this case it is very very small number. \n",
    "\n",
    "`'transform'` refers to six values that rasterio uses to record the scale and the position of the raster. This can be used to convert x, y coordinates (in the specified crs, e.g., lon, lat) to i, j coordinates (row and col number on a raster, coordinates in image space). In this case, it gives you information about the step between x,y coodinates as you go across rows/columns, and the x,y coordinates that correspond to particular rows/columns.\n",
    "\n",
    "The *Affine Transform* convention can be read as follows for `Affine(a, b, c, d, e, f)`:\n",
    "* a = 0.25: width - each pixel is 0.25 degrees wide (longitude)\n",
    "* b = 0.0: rotation - the grid is not \"tilted\" horizontally\n",
    "* c = -180.0: x-origin - the longitude at the far-left edge of the image (column 0)\n",
    "* d = 0.0: rotation - the grid is not \"title\" vertically\n",
    "* e = -0.25: height - each pixel is 0.25 degrees tall (latitude); the negative sign means the numbers go down as you go down the rows\n",
    "* f = 90.0: y-origin - the latitude at the top edge of the image (row 0)\n",
    "\n",
    "If you ever see b or d are not zero, it means the data was not collected from straight overhead, or the data has been re-projected at an angle. But most of the time they will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This translates x, y to row, col\n",
    "dataset.index(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This translates row, col to x, y\n",
    "dataset.xy(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Image/index_xy.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we see numbers like 89.87499999999991?\n",
    "\n",
    "This is *floating point \"noise\"*. Computers store numbers in binary (base 2). While a human can easily write $0.1$, a computer has to approximate it using fractions of powers of 2 (like $1/2, 1/4, 1/8...$). Some decimal numbers cannot be represented perfectly in binary, leading to tiny \"rounding residuals\" at the 14th or 15th decimal place.\n",
    "\n",
    "An implication is we will need to be careful if we are trying to filter on specific coordinates using precise decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the row and column indices of a particular coordinate?\n",
    "dataset.index(-120, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the coordinates of particular indices?\n",
    "print(dataset.xy(279, 120))\n",
    "print(dataset.xy(279, 119))\n",
    "print(dataset.xy(280, 120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster data as numpy arrays\n",
    "\n",
    "When you `rasterio.open()` something, you are not actually reading the whole raster file. You are only reading the metadata. This is a really nice property because sometimes a geotiff file could be too large to fit into your memory, and rasterio lets you read only parts of that image.\n",
    "\n",
    "Now we want to actually read the real data. For this we use the rasterio `read()` method, and specify what dimension or band we want to load.\n",
    "\n",
    "In this case there is only one band. If there were more you need need to use the metadata or other documentation of your TIF file to understand the nature of the bands and identify what you wnat to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first dimension of the array (there's only one)\n",
    "band = dataset.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a numpy array that you can operate on. You can do any kind of map algebra as long as it doesn't change the georeferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How dows it look?\n",
    "band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your color palette to use in your heat map\n",
    "nodes = [0, 0.5, 1]  # positions for each color from 0-1: 0 to vmin, 1 to vmax\n",
    "color_scheme = ['white', 'yellow', 'red']  # corresponds to nodes\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\n",
    "    'custom_name', list(zip(nodes, color_scheme)))\n",
    "custom_cmap.set_under('lightblue')  # set values under vmin to blue - mostly water bodies\n",
    "custom_cmap.set_over('purple')  # set values over vmax to purple\n",
    "custom_cmap.set_bad('gray') # set NaN/missing values to gray - shouldn't be relevant in this case as missings have a numerical value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **plot the raster band array** using `imshow` from matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a figure environment\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Add a layer of showing the heat map\n",
    "ax.imshow(band, # Data\n",
    "          cmap = custom_cmap, # Color information\n",
    "          extent = (-180, 180, -90, 90), # x, y scale\n",
    "          vmin = 0, vmax = 500000) # set thresholds for extreme values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a **colorbar**, assign the ax.imshow to a data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Assigning ax.imshow() to data object im\n",
    "# imshow method automatically add the heat map layer\n",
    "im = ax.imshow(band, # Data\n",
    "          cmap = custom_cmap, # Color information\n",
    "          extent = (-180, 180, -90, 90), # x, y scale\n",
    "          vmin = 0, vmax = 100000)\n",
    "fig.colorbar(im)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Population of the World in 2000 (Source: CIESIN 2018)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zooming in by using set_xlim and set_ylim methods\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "im = ax.imshow(band, # Data\n",
    "          cmap = custom_cmap, # Color information\n",
    "          extent = (-180, 180, -90, 90), # x, y scale\n",
    "          vmin = 0, vmax = 100000)\n",
    "\n",
    "fig.colorbar(im)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Population of the World in 2000: Europe')\n",
    "\n",
    "ax.set_xlim((-20, 50))\n",
    "ax.set_ylim((30, 70))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the colors? \n",
    "\n",
    "nodes = [0, 0.25, 0.5, 0.75, 1]  # positions for each color from 0-1\n",
    "color_scheme = ['white', 'bisque', 'yellow', 'olivedrab', 'navy']  # corresponds to nodes\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\n",
    "    'custom_name', list(zip(nodes, color_scheme)))\n",
    "custom_cmap.set_under('lightblue')  # set values under vmin to gray\n",
    "custom_cmap.set_over('purple')  # set values over vmax to black\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "im = ax.imshow(band, # Data\n",
    "          cmap = custom_cmap, # Color information\n",
    "          extent = (-180, 180, -90, 90), # x, y scale\n",
    "          vmin = 0, vmax = 200000)\n",
    "\n",
    "fig.colorbar(im)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Population of the World in 2000: Europe')\n",
    "\n",
    "ax.set_xlim((-20, 50))\n",
    "ax.set_ylim((30, 70))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change colors as you want.\n",
    "\n",
    "<img src=\"Image/colors.png\" width = \"500\">\n",
    "[Link](https://matplotlib.org/3.3.2/gallery/color/named_colors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing map algebra\n",
    "\n",
    "Let's practice doing some map algebra by mapping log population density over the world.\n",
    "\n",
    "To do this, we will need\n",
    "* To figure out how large each grid cell is (the $\\delta$), and the edges of the grid;\n",
    "* To assume that 1 degree of latitude is 111.11 km and that 1 degree of longitude at the equator is 111.11 km;\n",
    "* To create a lat-lon grid so that you can compute an array that is the same size as the original data set but where each element describes the area of the grid cell;\n",
    "* To use map algebra to convert $population$ to $population/area$ to $\\log_{10}(population/area)$, i.e. so a value of 1 indicates a density of 10 people per sq. km, 2 indicates a density of 100 people per sq. km, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll follow a *manual* approach where we build a grid of latitudes and longitudes. \n",
    "The resolution or $\\delta$ of the image is 15 arcminutes, or .25 degrees.\n",
    "The center of each pixel is therefore located $\\delta/2$ from the edge, so let's define two arrays representing the latitude and longitude of each pixel center (starting $\\delta/2$ from the edges of the image, which are -180 and 180 for longitude, and 90 and -90 for latitude).\n",
    "Then, we make a meshgrid of these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = .25 # from the metadata\n",
    "lons = np.arange(start=-179.875, stop=179.875 + delta, step=delta)\n",
    "# note the reversed direction of the step below, because we are going from north to south\n",
    "lats = np.arange(start=89.875, stop=-89.875 - delta, step=-delta)\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we examined the numpy array `band` earlier, we saw many values of -3.402823e+38. This is how \"negative infinity\" is stored, and represents grid cell containing no individuals. We will have to change this before calculating population density.\n",
    "\n",
    "Now, on to the calculation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latitude (y): 1 deg = 111.11 km\n",
    "# Longitude (x): 1 deg = 111.11 * cos(latitude in radian) km\n",
    "# Cell size is 0.25 degrees\n",
    "# Area = Ykm * Xkm\n",
    "area = (111.11 * .25) * (111.11 * .25 * np.cos(lat_grid / 180 * np.pi))\n",
    "# handle negative values\n",
    "band[band < 1e-1] = 1e-1\n",
    "log10_density = np.log10(band / area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map it!\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(log10_density, cmap=custom_cmap,\n",
    "               extent=(-180, 180, -90, 90),\n",
    "               vmin=0, vmax=3)\n",
    "fig.colorbar(im)\n",
    "# label axes and title\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('log10(Population Density) (Source: CIESIN 2018)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's follow a more dynamic approach where we draw directly on the metadata, so can be more flexible. We could run the below code on the GPW data at any resolution and it would go through perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Extract the relevant metadata\n",
    "transform = dataset.transform # Affine matrix which records the grid setup\n",
    "height = dataset.height # number of rows\n",
    "width = dataset.width # number of columns\n",
    "\n",
    "# 2) Get the latitudes of the centers of all pixels, to adjust area calculations\n",
    "\n",
    "# Need to know latitude of every pixel to get correct pixel area\n",
    "rows = np.arange(height) # latitude coordinates are what we care about\n",
    "cols = np.zeros(height) # we do not care about longitude coordinates - set to 0\n",
    "# Transform * (cols, rows) gives the (x, y) coordinates for each (col, row) combination\n",
    "# This gets coordinates directly rather than building them ourselves\n",
    "# This returns two arrays: longitudes (which will all be the same), and latitudes\n",
    "# We use _ to indicate that we don't save the first result of the calculation - the longitudes\n",
    "_, lats = transform * (cols, rows)\n",
    "\n",
    "# The transform points to the top-left corner of a pixel\n",
    "# We want to use the latitude in the center for more exact calculations\n",
    "# (0.5 * transform.e) is half the pixel height (usually -0.125)\n",
    "lats_centers = lats + (0.5 * transform.e)\n",
    "\n",
    "# 3) Area calculation\n",
    "# Use 111.132 km per degree as a standard constant (more precise)\n",
    "km_per_deg_lat = 111.132\n",
    "\n",
    "# figure out the height and widght of each pixel in km\n",
    "delta_lat = abs(transform.e) # 0.25\n",
    "delta_lon = abs(transform.a) # 0.25\n",
    "# height is fixed\n",
    "cell_height_km = delta_lat * km_per_deg_lat\n",
    "# width varies by the cosine of the latitude\n",
    "cell_widths_km = delta_lon * (km_per_deg_lat * np.cos(np.radians(lats_centers)))\n",
    "# calculate area\n",
    "areas = cell_height_km * cell_widths_km\n",
    "\n",
    "# 4) Set up 2D area grid to match with population data\n",
    "# Note that right now we have a 1D array of numbers, because these values are the same for every latitude\n",
    "# Rather than duplicating for every latitude, just create 2D array by making a column vector\n",
    "# This will take advantage of numpy's broadcasting ability, where it can do math between arrays of different shapes\n",
    "area_grid_2d = areas[:, np.newaxis]\n",
    "\n",
    "# 5) Density and log calculation\n",
    "# Using np.where avoids warnings about log(0) or dividing by zero\n",
    "density = np.where(band > 0, band / area_grid_2d, np.nan)\n",
    "log10_density = np.log10(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map it!\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(log10_density, cmap=custom_cmap,\n",
    "               extent=(-180, 180, -90, 90),\n",
    "               vmin=0, vmax=3)\n",
    "fig.colorbar(im)\n",
    "# label axes and title\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('log10(Population Density) (Source: CIESIN 2018)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Masking\n",
    "\n",
    "A useful operation with spatial data is masking. Masking allows you to hide or 'mask' or clip specific areas, to make a cleaner figure.\n",
    "\n",
    "Suppose we were interested in the population of France, and wanted to only show population data for France. \n",
    "\n",
    "We will first load a shapefile with the boundaries of France, which we can then use as a mask for the population raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load France shp file\n",
    "fra = gpd.read_file('Data/gadm41_FRA_0.shp')\n",
    "fra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we erase the areas which are out of France? With the `rasterio.mask.mask()` function, we can clip the raster with the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_array, _ = rasterio.mask.mask(dataset, fra.geometry, nodata = -1)\n",
    "print(clipped_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove single-dimensional entries from the shape of an array.\n",
    "# using np.squeeze\n",
    "clipped_array = clipped_array.squeeze(axis = 0)\n",
    "print(clipped_array.shape)\n",
    "clipped_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out the right coordinates to zoom on France\n",
    "fra.geometry[0].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting starts\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(clipped_array, cmap=custom_cmap,\n",
    "               extent=(-180, 180, -90, 90),\n",
    "               vmin=0, vmax=200000)\n",
    "fig.colorbar(im)\n",
    "\n",
    "# Zoom in on France using it coordinates\n",
    "ax.set_xlim((fra.geometry[0].bounds[0]-1, fra.geometry[0].bounds[2]+1))\n",
    "ax.set_ylim((fra.geometry[0].bounds[1]-1, fra.geometry[0].bounds[3]+1))\n",
    "\n",
    "# Label axes and title\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Population of France in 2000 (Source: CIESIN 2018)')\n",
    "\n",
    "# Extra\n",
    "ax.fill(-110,15,color='gray', label='Unpopulated')\n",
    "ax.legend(loc=3, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine transformations and masking\n",
    "\n",
    "Suppose we want to mask particular polygons. Let's work with a map for administrative units in France - regions.\n",
    "\n",
    "We can load and map these boundaries easily using `geopandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file('Data/gadm41_FRA_1.shp') \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "df.plot(ax=ax, color='white', edgecolor='black')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('France')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we create a mask for one administrative unit?\n",
    "Previously, we created a mask using raterio.mask.mask:\n",
    "\n",
    "```\n",
    "band = rasterio.open('Data/GPW.tif').read(1)\n",
    "fra = gpd.read_file('Data/gadm41_FRA_0.shp')\n",
    "clipped_array, _ = rasterio.mask.mask(dataset, fra.geometry, nodata = -1).squeeze(axis=0)\n",
    "\n",
    "```\n",
    "\n",
    "We do not have such a `rasterio` file at the moment. We would need to create a raster file first. \n",
    "More precisely, we need to convert the shape file of France regions (`df`) into a raster data. We will focus on a single region.\n",
    "\n",
    "What we will utilize is `Affine` that divides the shape file by numerous pieces and fits it into a rectangular box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import geometry_mask\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(Affine) # Focus on the 2-D transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we do not need to memorize all the transformation types presented in the help. The ```Affine``` function provides a more intuitive way of doing affine transformations. We focus on **the destination of the transformation**, not the departure. \n",
    "\n",
    "As we discussed before, affine transformations are set up as follows: \n",
    "\n",
    "Affine(a, b, c, d, e, f)\n",
    "- a = width 'resolution' of a pixel\n",
    "- b = row rotation (typically zero) # \n",
    "- c = x-coordinate of the upper-left corner of the upper-left pixel\n",
    "- d = column rotation (typically zero)\n",
    "- e = height 'resolution' of a pixel (typically negative)\n",
    "- f = y-coordinate of the of the upper-left corner of the upper-left pixel\n",
    "##### see more in https://docs.geotools.org/latest/userguide/tutorial/affinetransform.html\n",
    "\n",
    "Let's move forward supposing we want pixels at a 0.1 degree resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the total bounds of France (not just the region)\n",
    "xmin, ymin, xmax, ymax = df.total_bounds\n",
    "\n",
    "print(f\"Extent: {xmin}, {ymin}, {xmax}, {ymax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a set of information regarding the 'destination' of our shape file. We further need the `geometry_mask` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(geometry_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save just the region\n",
    "ara = df.iloc[0]\n",
    "\n",
    "# Set target resolution\n",
    "res = 0.05\n",
    "\n",
    "# Define target dimensions clearly\n",
    "width = int(np.round((xmax - xmin) / res))\n",
    "height = int(np.round((ymax - ymin) / res))\n",
    "\n",
    "# Set up the mask\n",
    "masks = geometry_mask(\n",
    "        geometries = [df.iloc[0].geometry], # Geometry of the shape you want to analyze, wrap in brackets because it expects a list\n",
    "        out_shape = (height, width),\n",
    "        transform = Affine(res, 0, xmin, 0, -res, ymax), # Destination information\n",
    "        all_touched=True, # Including all the pixels if boundaries just 'touch' them\n",
    "        invert=True) # pixels inside the geometry are 1 instead of 0, the default for a 'mask'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Plot the mask raster\n",
    "plt.imshow(masks, extent=(xmin, xmax, ymin, ymax), cmap='gray_r', alpha=0.6)\n",
    "# 2. Plot the region boundaries \n",
    "df.boundary.plot(ax=plt.gca(), color='black', linewidth=1)\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Mask of ARA Region\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine this with the population raster data! We'll directly apply the mask to the population data, and show the result.\n",
    "\n",
    "An issue is that we defined the mask for France only, but the population data are global. Let's redefine the mask so it applies globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the mask\n",
    "global_mask = geometry_mask(\n",
    "        geometries = [df.iloc[0].geometry], # Geometry of the shape you want to analyze, wrap in brackets because it expects a list\n",
    "        out_shape = dataset.shape,\n",
    "        transform = dataset.transform, # Destination information\n",
    "        all_touched=True, # Including all the pixels if boundaries just 'touch' them\n",
    "        invert=True) # pixels inside the geometry are 1 instead of 0, the default for a 'mask'\n",
    "\n",
    "# Prepare the data: Mask the population array\n",
    "# We use np.where to keep data only where masks == 1, else set to NaN\n",
    "# This makes the \"unwanted\" areas perfectly transparent\n",
    "plot_data = np.where(global_mask == 1, clipped_array, np.nan)\n",
    "\n",
    "# Plotting starts\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Plot population\n",
    "im = ax.imshow(plot_data, cmap=custom_cmap,\n",
    "               extent=(-180, 180, -90, 90),\n",
    "               vmin=0, vmax=200000)\n",
    "fig.colorbar(im, ax=ax, label=\"Population\", shrink=0.8)\n",
    "\n",
    "# Plot the region boundaries \n",
    "df.boundary.plot(ax=ax, color='black', linewidth=1)\n",
    "\n",
    "# Zoom in on France using its total bounds we saved earlier\n",
    "ax.set_xlim(xmin,xmax)\n",
    "ax.set_ylim(ymin,ymax)\n",
    "\n",
    "# Label axes and title\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Population of ARA in 2000 (Source: CIESIN 2018)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Working with multidimensional data\n",
    "\n",
    "The GPW raster had only one static band, but often we will be working with multidimensional raster data, where each pixel/point has multiple variables/pieces of information associated with it. \n",
    "\n",
    "We will review using `xarray`s as a useful way for working with raster data that can accommodate such rasters.\n",
    "\n",
    "First, we'll import the `xarray` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Overview of `xarray`\n",
    "\n",
    "<img src=\"Image/xarray.jpeg\" width = \"900\">\n",
    "\n",
    "`xarray` is a great tool for handling high dimensional arrays, for example meteorological/atmospheric data over time.\n",
    "\n",
    "- What is a high dimensional array? 3-D, 4-D, 5-D...\n",
    "- Why is it useful? To store dynamic fields.\n",
    "- A heuristic explanation: Tonnes of rasters in one data object\n",
    "    - In `rasterio`, each band has one static field. That means, one location, one number.\n",
    "    - In `xarray`, one data object can contain dynamic fields. That means, one location, many numbers or a lot of sets of information.\n",
    "\n",
    "#### Some useful links:\n",
    "- [Why do we want to use `xarray`?](http://xarray.pydata.org/en/stable/why-xarray.html)\n",
    "- [Core data structure](http://xarray.pydata.org/en/stable/why-xarray.html)\n",
    "- Two basic sorts of functionality:\n",
    "    - [Apply operations over dimensions](http://xarray.pydata.org/en/stable/computation.html)\n",
    "    - [Indexing](http://xarray.pydata.org/en/stable/indexing.html)\n",
    "    \n",
    "#### NetCDF4?\n",
    "NetCDF (network Common Data Form, or .nc) is a file format for storing multidimensional scientific data (variables) such as temperature, humidity, pressure, wind speed, and direction. \n",
    "\n",
    "Let's use `xarray` to open a multidimensional raster of rainfall data over time in Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('Data/AustraliaRainfall.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Description\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us?\n",
    "* Data are monthly rainfall in mm for 1970-2007.\n",
    "* The dataset has 4 dimensions that uniquely identify an observation: lat, lon, year, and month.\n",
    "* The variable defined for each observation is called `rainfall`. Note that some rasters could have multiple bands with additional variables defined at each coordinate in the given dimensions.\n",
    "\n",
    "How many values does each dimension take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions (of addresses)\n",
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the coordinates (or addresses)\n",
    "# Here, 'coords' are not restricted to indicating longitude and latitude.\n",
    "ds.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which datasets does ds have for each set of address?\n",
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the rainfall dataset\n",
    "ds['rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accessing the rainfall values\n",
    "ds['rainfall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of the rainfall values? This is a 4-dimensional object\n",
    "ds['rainfall'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic way of indexing. What does this mean?\n",
    "ds['rainfall'].values[:, :, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing based on sel method\n",
    "# This is the same as above! \n",
    "ds['rainfall'].sel(year = 1971, month = 6).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting multidimensional data\n",
    "\n",
    "Now let's plot these data. To start out, we'll plot the data in 2 dimensions. That means we'll have to restrict the data we are trying to plot.\n",
    "\n",
    "Let's restrict to a particular year and month to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting with imshow\n",
    "plt.imshow(ds['rainfall'].sel(year = 1971, month = 6), origin = 'lower')\n",
    "# origin = 'upper' is the default. The value in the location (0, 0) to the left-top corner.\n",
    "# origin = 'lower' puts the value in the location (0, 0) to the left-bottom corner. \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `xarray`'s built-in plotting, which retains associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the differences between this and the figure using the imshow function?\n",
    "ds['rainfall'].sel(year=1971, month=6).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to plot **data over time**? We will need to restrict the space dimensions.\n",
    "\n",
    "For example, let's plot monthly rainfall for 2000 in an arbitrary location in Australia, and annual rainfall in April for the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "ds['rainfall'].sel(year = 2000, lat = -27, lon = 135).plot(ax=ax0)\n",
    "ds['rainfall'].sel(month = 4, lat = -27, lon = 135).plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations with `xarray`\n",
    "\n",
    "`xarray` has a variety of methods we can use to perform calculations. For example, let's calculate mean rainfall for January across years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['rainfall'].sel(month = 1).mean(dim = 'year').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this plotting?\n",
    "ds['rainfall'].mean(dim = 'month').max(dim = 'year').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this plotting?\n",
    "ds['rainfall'].sum(dim = 'month').mean(dim = 'year').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a nice plot of mean monthly rainfall by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(14, 12), sharex=True, sharey=True)\n",
    "\n",
    "# Flatten the 2D array of axes into a 1D list of 12 for easy looping\n",
    "axes = axes.flatten()\n",
    "month_names = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
    "                  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "# Loop through months 1 to 12\n",
    "for i, month in enumerate(range(1, 13)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Calculate and plot the mean for that specific month\n",
    "    data = ds['rainfall'].sel(month=month).mean(dim='year')\n",
    "    # Plot with 'add_colorbar=False' to keep the grid tidy, and add one colorbar at the end\n",
    "    im = data.plot(ax=ax, vmin=0, vmax=200, cmap='viridis', add_colorbar=False)\n",
    "    \n",
    "    # Clean up titles\n",
    "    ax.set_title(month_names[i])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "# Add a shared colorbar\n",
    "# Create colorbar axis, [left, bottom, width, height] in figure coordinates\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "# attach the colorbar to that axis\n",
    "fig.colorbar(im, cax=cbar_ax, label='Mean Monthly Rainfall (mm)')\n",
    "# Adjust spacing manually (Avoid tight_layout here)\n",
    "fig.subplots_adjust(right=0.90, top=0.95, wspace=0.1, hspace=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create new variables to plot by using **map algebra**.\n",
    "\n",
    "For example, let's calculate how mean rainfall in January compares to mean rainfall in other months across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create new variables to plot by using map algebra.\n",
    "jan_mean = ds['rainfall'].sel(month=1).mean(dim='year')\n",
    "month_mean = ds['rainfall'].mean(dim='month').mean(dim='year')\n",
    "((jan_mean - month_mean) / month_mean).plot(cmap='RdBu')\n",
    "# Explore https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
