{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf1f2bc-f975-4b3b-ae16-8af3a8567828",
   "metadata": {},
   "source": [
    "# Section 9. Text Analysis Practice\n",
    "\n",
    "#### Instructor: Pierre Biscaye\n",
    "\n",
    "The purpose of this notebook is to give you opportunities and challenge to practice applying the skills developed in the other notebooks. \n",
    "\n",
    "The content of this notebook is taken from UC Berkeley D-Lab's Python Text Analysis [course](https://github.com/dlab-berkeley/Python-Text-Analysis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d9243-6270-43ba-8526-c8d125787a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199519e3-896e-4085-a3a0-83ba137409bb",
   "metadata": {},
   "source": [
    "## Challenge 1: Extracting and Counting Substrings\n",
    "\n",
    "Adapting the code to extract twitter handle mentions from the twitter data, write code to extract all hashtags. Keep the results as lists. Then, using this information, calculate the count of mentions for each hashtag across all tweets. Plot a bar chart of mentions for the 10 most common hashtags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e8189-65e7-4a36-84c6-28fd657847b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the separator to be comma\n",
    "tweets = pd.read_csv('Data/airline_tweets.csv', sep=',')\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb457d-4b53-4e84-8185-ac6c3481cc13",
   "metadata": {},
   "source": [
    "## Challenge 2: Preprocessing with Multiple Steps\n",
    "\n",
    "So far we've learned a few preprocessing operations, let's put them together in a function! This function would be a handy one to refer to if you happen to work with some messy English text data, and you want to preprocess it with a single function. \n",
    "\n",
    "The below code reads in example text data for this challenge. Write a function to:\n",
    "- Lowercase the text\n",
    "- Remove punctuation marks\n",
    "- Remove extra whitespace characters\n",
    "\n",
    "Feel free to recycle the code we used in the other notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36bd0b-579d-44f8-9fa2-d5a9dc5b250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge1_path = 'Data/example1.txt'\n",
    "\n",
    "with open(challenge1_path, 'r') as file:\n",
    "    challenge1 = file.read()\n",
    "    \n",
    "print(challenge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f61b49-5032-4c2b-b0b4-ab2400f50a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "    '''Remove punctuation marks in input text'''\n",
    "    \n",
    "    # Select characters not in puncutaion\n",
    "    no_punct = []\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            no_punct.append(char)\n",
    "\n",
    "    # Join the characters into a string\n",
    "    text_no_punct = ''.join(no_punct)   \n",
    "    \n",
    "    return text_no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380a327-1a75-4181-9915-7ee1700aea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a pattern in regex\n",
    "blankspace_pattern = r'\\s+'\n",
    "\n",
    "# Write a replacement for the pattern identfied\n",
    "blankspace_repl = ' '\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Step 1: Lowercase the input text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Step 2: Use remove_punct to remove puncutuation marks\n",
    "    text = remove_punct(text)\n",
    "\n",
    "    # Step 3: Remove extra whitespace characters\n",
    "    text = re.sub(blankspace_pattern, blankspace_repl, text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33994f-b24a-4b12-a63a-2ef8057edfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(challenge1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25616f6a-2c3d-4004-9d78-73b1cb4c3e6d",
   "metadata": {},
   "source": [
    "## Challenge 3: Remove Stop Words\n",
    "\n",
    "We have known how `nltk` and `spaCy` work as NLP packages. We've also demostrated how to identify stop words with each package. \n",
    "\n",
    "Let's write **two** functions to remove stop words from our text data. \n",
    "\n",
    "- Complete the function for stop words removal using `nltk`\n",
    "    - The starter code requires two arguments: the raw text input and a list of predefined stop words\n",
    "- Complete the function for stop words removal using `spaCy`\n",
    "    - The starter code requires one argument: the raw text input\n",
    " \n",
    "A little reminder before we dive in: both functions take raw text as input, so that's a signal to perform tokenization on the raw text first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22c991-bd26-499c-bdf7-cdec2043ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "def remove_stopword_nltk(raw_text, stopword):\n",
    "    \n",
    "    # Step 1: Tokenization with nltk\n",
    "    tokens = word_tokenize(raw_text)\n",
    "    \n",
    "    # Step 2: Filter out tokens in the stop word list\n",
    "    text = [token for token in tokens if token not in stopword]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148dab5-64aa-4585-bcd8-4e4f1f65fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def remove_stopword_spacy(raw_text):\n",
    "\n",
    "    # Step 1: Apply the nlp pipeline\n",
    "    doc = nlp(raw_text)\n",
    "    \n",
    "    # Step 2: Filter out tokens in the stop word list\n",
    "    text = [token.text for token in doc if token.is_stop is False]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a9c53-7bcc-49b7-9ad4-6061eef94fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tweets['text'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c182f-9091-42f5-8a2a-0b38322a0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopword_nltk(text, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e4a8b-bfee-4ea2-bb7d-00e31d870e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopword_spacy(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff891a-2815-40fc-96e8-c4b292c2b956",
   "metadata": {},
   "source": [
    "## Challenge 4: Find the Word Boundary\n",
    "\n",
    "Now we know that tokenization in BERT often returns subwords. Let's try a few more examples! \n",
    "\n",
    "Do the results make sense to you? What do you think is the correct word boundary to split the following words into subwords? \n",
    "\n",
    "Also feel free to read more about limitations of the WordPiece algorithm. For instance, [this blog post](https://medium.com/@rickbattle/weaknesses-of-wordpiece-tokenization-eb20e37fec99) dives into reasons why does it fail, and [this one](https://tinkerd.net/blog/machine-learning/bert-tokenization/#demo-bert-tokenizer) introduces the mechanism underlying the algoritm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43380209-25b7-4593-a60d-1be58eac528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# Initialize the tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_tokens(string):\n",
    "    '''Tokenize the input string with BERT'''\n",
    "    tokens = tokenizer.tokenize(string)\n",
    "    return print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e605c1-fb19-4899-a3f9-acce0db680b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abbreviations\n",
    "get_tokens('Clermont-Ferrand')\n",
    "\n",
    "# Prefix\n",
    "get_tokens('unstoppable')\n",
    "\n",
    "# Digits\n",
    "get_tokens('378')\n",
    "\n",
    "# YOUR EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32551dc-1077-445d-aace-f82fcb552066",
   "metadata": {},
   "source": [
    "## Challenge 5: Words with Highest Mean TF-IDF scores\n",
    "\n",
    "In notebook 9b, we got tf-idf values for each term in each document. Does that inform us anything about our data? Instead of focusing on the tf-idf value of any particular word, let's take a step back. Are there any words that are particularly informative for tweets that have been classified as positive/negative? \n",
    "\n",
    "Let's gather the indices to all positive/negative tweets, and calculate the mean tf-idf scores of words appear in positive/negative tweets. \n",
    "\n",
    "We've provided the following starter codes to scaffold:\n",
    "- Use boolean masks to select tweets that have positive/negative sentiments, retrieve the indices, and assign them to `positive_index`/`negative_index`\n",
    "- Select positive/negative tweets in the tfidf dataframe, and take the mean tf-idf values across the documents, sort the mean values in the descedning order, and get the top 10 terms. \n",
    "\n",
    "After you've completed the following two cells, you can plot the words having the highest mean tf-idf scores for each subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687401d9-6a8a-4832-a064-3fa285279bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tweets = pd.read_csv('Data/tweets_clean.csv', sep=',')\n",
    "\n",
    "# Create a tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             stop_words='english',\n",
    "                             min_df=2,\n",
    "                             max_df=0.95,\n",
    "                             max_features=None)\n",
    "\n",
    "# Fit and transform \n",
    "tf_dtm = vectorizer.fit_transform(tweets['text_lemmatized'])\n",
    "\n",
    "# Create a tf-idf dataframe\n",
    "tfidf = pd.DataFrame(tf_dtm.todense(),\n",
    "                     columns=vectorizer.get_feature_names_out(),\n",
    "                     index=tweets.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa612ae-00c6-4ebb-8feb-d7f97c62c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the boolean masks \n",
    "positive_index = tweets[tweets['airline_sentiment'] == 'positive'].index\n",
    "negative_index = tweets[tweets['airline_sentiment'] == 'negative'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e03dc-f46d-449c-9087-3b8f551debf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the following two lines\n",
    "pos = tfidf.loc[positive_index].mean().sort_values(ascending=False).head(10)\n",
    "neg = tfidf.loc[negative_index].mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a02ed4-e279-4a8d-8097-e07b4f9a1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.plot(kind='barh', \n",
    "         xlim=(0, 0.18),\n",
    "         color='cornflowerblue',\n",
    "         title='Top 10 terms with the highest mean tf-idf values for positive tweets');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4551b9a-8cb3-4ead-abc2-42d8cf13289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg.plot(kind='barh', \n",
    "         xlim=(0, 0.18),\n",
    "         color='darksalmon',\n",
    "         title='Top 10 terms with the highest mean tf-idf values for negative tweets');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569bb3c-97f5-4ea5-b4a1-41e27967d8fc",
   "metadata": {},
   "source": [
    "How do you interpret these two plots? Are there any words that don't really make sense to you? Do the results suggest a need for any additional preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08e625-3ffa-486c-b3d0-a1a7a8b6bd23",
   "metadata": {},
   "source": [
    "## Challenge 6: Doesn't Match\n",
    "\n",
    "We have a list of tuples for coffee-noun pairs. Let's find out which coffee drink is most commonly associated with the word \"coffee,\" and which one is not. Complete the for loop to calculate the cosine similarity between each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba9893-5bf8-400c-9432-5d6fb1d72d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format('Data/GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d82762-f314-4f0a-a248-c1ff9caefd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_nouns = [\n",
    "    ('coffee', 'espresso'),\n",
    "    ('coffee', 'cappuccino'),\n",
    "    ('coffee', 'latte'),\n",
    "    ('coffee', 'americano'),\n",
    "    ('coffee', 'irish'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95448c-eb1a-4bda-bac4-745b6c55af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cosine similarities between each pair\n",
    "for w1, w2 in coffee_nouns:\n",
    "    similarity = wv.similarity(w1, w2)\n",
    "    print(f\"{w1}, {w2}, {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e50a4f-6980-44ea-9d2d-35229fa68c64",
   "metadata": {},
   "source": [
    "Next, look up the documentation for the [`doesnt_match`](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#word2vec-demo) function. We will use it to identify the verb in the following list (one cell below) that does not seem to belong.\n",
    "\n",
    "Use `doesnt_match` to find the verb that is unlikely to fit within the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61134261-9596-4ec1-be7d-0d6bfe195528",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_verbs = ['brew', 'drip', 'pour', 'make', 'grind', 'roast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56f67a-20c5-4002-baf8-160921d7a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the word that doesn't belong to the list\n",
    "verb_dosent_match = wv.doesnt_match(coffee_verbs)\n",
    "verb_dosent_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448ce9c-501d-460b-8e5e-5ade889a511f",
   "metadata": {},
   "source": [
    "## Challenge 7: Gender bias in word embeddings\n",
    "\n",
    "[Bolukbasi et al. (2016)](https://arxiv.org/pdf/1607.06520) is a thought-provoking investigation of gender bias in word embeddings. They primarily focus on word analogies, especially those that reveal gender stereotyping. Let run a couple examples discussed in the paper, using the `most_similiar` function we've just learned. \n",
    "\n",
    "The following code block contains a few examples we can pass to the `positive` argument: we want the output to be similar to, for example, `woman` and `chairman`, and in the meantime, we are also specificying that it should be dissimilar to `man`. We'll print the top result by indexing to the 0th item. \n",
    "\n",
    "Let's complete the following for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26910669-83a3-438c-bea5-89b2150db6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pair = [['woman', 'chairman'],\n",
    "                 ['woman', 'doctor'], \n",
    "                 ['woman', 'computer_programmer'],\n",
    "                 ['woman', 'pilot']]\n",
    "negative_word = 'man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7883e-b9e6-4aa3-82fa-a0b479bc9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most similar word given positive and negative examples\n",
    "for example in positive_pair:\n",
    "    result = wv.most_similar(positive=example, negative=negative_word)\n",
    "    print(f\"man is to {example[1]} as woman is to {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81e848-3f42-4c42-a841-2359de9a767f",
   "metadata": {},
   "source": [
    "**Question**: What do you find? Are these results surprising?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
