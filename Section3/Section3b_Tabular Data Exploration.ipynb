{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675a7815",
   "metadata": {},
   "source": [
    "# Section 3. Tabular Data Exploration\n",
    "\n",
    "#### Instructor: Pierre Biscaye\n",
    "\n",
    "The content of this notebook draws on material from Gabor's Data Analysis in Python [course](https://github.com/gabors-data-analysis/da-coding-python).\n",
    "    \n",
    "This notebook covers some additional basics of working with tabular data. \n",
    "It does not go into details of regression analysis or other econometrics as that is out of scope for the course. \n",
    "We will cover more details of regression analysis in a later notebook as we prepare to get into machine learning.  \n",
    "    \n",
    "### Sections\n",
    "    \n",
    "1. Descriptive statistics for data frames                       \n",
    "2. Checking for outliers\n",
    "3. Hypothesis testing\n",
    "4. Associations between variables\n",
    "   \n",
    "### Libraries loaded\n",
    "* pandas\n",
    "* matplotlib.pyplot\n",
    "* numpy\n",
    "* seaborn\n",
    "* scipy\n",
    "* statsmodels.formula.api\n",
    "\n",
    "### Files loaded\n",
    "* gapminder.csv   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580885c",
   "metadata": {},
   "source": [
    "### Let's start by importing packages we know we'll need\n",
    "\n",
    "Others will be introduced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdef28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2c866",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "We'll be using data from the billion price project. The Billion Prices [project](http://www.thebillionpricesproject.com/) collects online and offline prices of selected products sold by selected retailers. It was founded in 2008 by Alberto Cavallo and Roberto Rigobon and aims to collect price information all over the world. \n",
    "\n",
    "The data are available as a CSV online, so we can practice loading that directly into a data frame. \n",
    "\n",
    "*Note*: the encoding ensures special characters are read in correctly. Different encodings may be needed for different text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original = pd.read_csv(\"https://osf.io/yhbr5/download\", encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63337fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variables\n",
    "bpp_original.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2b23b",
   "metadata": {},
   "source": [
    "Let's **create a new variable**, the price difference between the online and offline price, using vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef319af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original[\"p_diff\"] = bpp_original[\"price_online\"] - bpp_original[\"price\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246c753",
   "metadata": {},
   "source": [
    "## 1. Descriptive statistics\n",
    "\n",
    "First, check all the variables in DataFrame using the built-in summary statistics method `describe()`. Note that this only applies to numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e476c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e3ef4",
   "metadata": {},
   "source": [
    "Compare key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original.filter([\"price\", \"price_online\", \"p_diff\"]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress scientific notation in Pandas\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "bpp_original.filter([\"price\", \"price_online\", \"p_diff\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bf6a0",
   "metadata": {},
   "source": [
    "We can also request specific percentiles in the summary stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original.filter([\"price\", \"price_online\", \"p_diff\"]).describe(percentiles=[0.25, 0.5, 0.75, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every 10th percentile\n",
    "bpp_original.filter([\"price\", \"price_online\", \"p_diff\"]).describe(percentiles = np.arange(0.1, 1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e6e4f",
   "metadata": {},
   "source": [
    "Put the descriptives into columns and variables into rows for a nicer looking table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e83e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sumstats = bpp_original.filter([\"price\", \"price_online\", \"p_diff\"]).describe().transpose()\n",
    "sumstats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb698b",
   "metadata": {},
   "source": [
    "Let's export this table as a csv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcacf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumstats.to_csv('bpp_sumstats.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829f70f",
   "metadata": {},
   "source": [
    "### Descriptive statistics by grouping variable.\n",
    "\n",
    "Let's look at price differences by country.\n",
    "\n",
    "For this, you need to group the data and apply the required statistics to the appropriate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dacfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original.groupby(\"COUNTRY\").agg(\n",
    "    mean_price_diff=(\"p_diff\", \"mean\"), median_price_diff=(\"p_diff\", \"median\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212a0a0",
   "metadata": {},
   "source": [
    "Let's create a new function calculating the range of values and add this to the descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_function(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "bpp_original.groupby(\"COUNTRY\").agg(\n",
    "    mean_price_diff=(\"p_diff\", \"mean\"),\n",
    "    median_price_diff=(\"p_diff\", \"median\"),\n",
    "    range_price_diff=(\"p_diff\", range_function),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c18d4",
   "metadata": {},
   "source": [
    "**Practice:** Load the gapminder.csv dataset. Aggregate the data by country, taking the max over years for lifeExp and gdpPercap. Print a table of descriptive statistics for this aggregated dataset, including the 95th percentile in addition to the default statistics. Pivot the table to show statistics as columns, and save it to your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381541bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = pd.read_csv('Data/gapminder.csv')\n",
    "gap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb903dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3dfca",
   "metadata": {},
   "source": [
    "## 2. Checking for outliers\n",
    "\n",
    "Before digging deep into analysis, it is useful to visualize the distribution of variables. This is particularly useful for checking for outliers which can unduly affect any analysis.\n",
    "\n",
    "Let's use the built in pandas `hist()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b18694",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp_original['price'].hist(bins=30); # remember that adding ; at the end clears a display of the type of output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e0667",
   "metadata": {},
   "source": [
    "It is clear: we need to filter out some outlier data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the max, compared to p75!\n",
    "bpp_original.filter([\"price\"]).describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c55b0d",
   "metadata": {},
   "source": [
    "Let's drop obvious **outliers** for price. \n",
    "\n",
    "One possibility is just eyeballing based on the histogram and choosing a round cutoff as a threshold for identifying outliers, such as $1000.\n",
    "\n",
    "Another possibility is taking a more statistical approach and identifying a percentile cutoff, such as the 95th or 99th percentile. \n",
    "\n",
    "After identifying a threshold for outliers, we have to decide how to deal with them. We could:\n",
    "1. Drop all observations of price above that threshold\n",
    "2. Set them to missing (which effectively drops them from any analysis)\n",
    "3. Replace them with other values.\n",
    "\n",
    "Replacing outliers with another value is called **imputation**. A common approach is to **winsorize** extreme values by replacing them with the median or the value at some cutoff point. It is a good idea to check the sensitivity of your analyses to how you deal with outliers.\n",
    "\n",
    "For now, let's drop rows where price is above the 95th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 95th percentile of the price column\n",
    "percentile_95 = bpp_original['price'].quantile(0.95)\n",
    "print(percentile_95)\n",
    "\n",
    "# Drop rows where price is above the 95th percentile\n",
    "bpp = bpp_original[bpp_original['price'] <= percentile_95]\n",
    "\n",
    "print(bpp.shape)\n",
    "print(bpp_original.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp.filter([\"price\", \"price_online\", \"p_diff\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp['price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f61fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how does the number of bins affect the usefulness of the plot?\n",
    "bpp['price'].hist(bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2702c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp['price'].hist(bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985cb78c",
   "metadata": {},
   "source": [
    "#### Kernel density\n",
    "\n",
    "Histogram or kernel density? A kernel density line is an approximation of the probability density function and is another useful way of plotting the distribution of a variable.\n",
    " \n",
    "We can plot kernel densities using the `seaborn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram with a KDE curve\n",
    "sns.histplot(bpp['price'], kde=True, bins=25, color='blue', alpha=0.5)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram and KDE for Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for price differences\n",
    "sns.histplot(bpp['p_diff'], kde=True, bins=25, color='blue', alpha=0.5)\n",
    "plt.xlabel('Price difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram and KDE for Price difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8f291",
   "metadata": {},
   "source": [
    "We still have some large outliers! Let's **trim** the  dataset to drop observations where the online price is above the 95th percentile in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad57b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 95th percentile of the price column\n",
    "percentile_95 = bpp_original['price_online'].quantile(0.95)\n",
    "print(percentile_95)\n",
    "print(bpp.shape)\n",
    "\n",
    "# Drop rows where price is above the 99th percentile\n",
    "bpp = bpp[bpp['price_online'] <= percentile_95]\n",
    "print(bpp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpp.filter([\"price\", \"price_online\", \"p_diff\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for price differences\n",
    "sns.histplot(bpp['p_diff'], kde=True, bins=25, color='blue', alpha=0.5)\n",
    "plt.xlabel('Price difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram and KDE for Price difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835079d0",
   "metadata": {},
   "source": [
    "**Practice:** Plot histograms of population and life expectancy in the gapminder dataset. Do there appear to be any outliers? Drop observations above the 99th percentile for any variable with large positive outliers, and plot the distribution again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03141595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69be953",
   "metadata": {},
   "source": [
    "## 3. Hypothesis testing \n",
    "\n",
    "All econometric analysis revolves around testing hypotheses about values in the data.\n",
    "\n",
    "Let's start with a simple hypothesis tests about whether there is any difference between online and offline prices for the goods in this sample.\n",
    "\n",
    "Test 1: \n",
    "\n",
    "H0: the average price difference between price_online - price = 0 \\\n",
    "HA: the average price diff is non-0.\n",
    "\n",
    "We will use the `stats` package from the `scipy` library for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(bpp[\"p_diff\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e896444",
   "metadata": {},
   "source": [
    "*Question*: What do we conclude?\n",
    "\n",
    "Let us create multiple hypothesis tests to check the hypothesis that online prices are the same as offline for each country!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = bpp.groupby(\"COUNTRY\").agg(\n",
    "    mean_pdiff=(\"p_diff\", \"mean\"),\n",
    "    se_pdiff=(\"p_diff\", \"sem\"),\n",
    "    num_obs=(\"p_diff\", \"count\"),\n",
    ")\n",
    "testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42b7b1",
   "metadata": {},
   "source": [
    "With these statistics we can calculate t-stats for the null hypothesis that the difference is 0 in each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing[\"t_stat\"] = testing[\"mean_pdiff\"] / testing[\"se_pdiff\"]\n",
    "testing[\"p_val\"] = stats.t.sf(abs(testing[\"t_stat\"]), df=testing[\"num_obs\"] - 1).round(4)\n",
    "testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeea3e5",
   "metadata": {},
   "source": [
    "*Econometrics review*: Interpret the results for each country.\n",
    "\n",
    "What are the possible dangers of multiple hypothesis testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e706c1",
   "metadata": {},
   "source": [
    "## 4. Association\n",
    "\n",
    "We are generally most interested in analyzing the relationship between two or more variables.\n",
    "\n",
    "A good way to start is by plotting variables against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e15f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(bpp['price_online'], bpp['price'], alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4ed57",
   "metadata": {},
   "source": [
    "If all the points were on the 45 degree line, that would indicate that two values are perfectly equal.\n",
    "\n",
    "Let's add a 45 degree line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b433ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(bpp['price_online'], bpp['price'], alpha=0.6)\n",
    "plt.axline([0, 0], [1, 1], color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226607b5",
   "metadata": {},
   "source": [
    "We can also estimate the linear relationship between the two variables using a linear regression, and add that to the plot.\n",
    "\n",
    "Let's use the `linregress` function from the `scipy` `stats` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.linregress(bpp['price_online'], bpp['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract individual elements\n",
    "slope=stats.linregress(bpp['price_online'], bpp['price']).slope\n",
    "intc=stats.linregress(bpp['price_online'], bpp['price']).intercept\n",
    "slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed0d9a",
   "metadata": {},
   "source": [
    "Let's use these results to add the regression line to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(bpp['price_online'], bpp['price'], alpha=0.6)\n",
    "plt.axline([0, 0], [1, 1], color='black', label='45 degree line')\n",
    "plt.axline(xy1=(0,intc), slope=slope, color='red', label='Linear regression') # plot line with a point and a slop\n",
    "plt.ylabel('Price', fontsize=12)\n",
    "plt.xlabel('Price Online', fontsize=12)\n",
    "plt.title('Association between price online vs offline', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64a453",
   "metadata": {},
   "source": [
    "*Question*: What do you conclude from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac239b",
   "metadata": {},
   "source": [
    "### Running regressions\n",
    "\n",
    "There are many packages for running regressions in python. Another common one is the statsmodels formula api from the `statsmodels` library. This function allows you to specify the regression equation as a string, and produces output tables similar to what you might see in Stata or R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_reg = smf.ols(\"price ~ price_online\", data=bpp).fit()\n",
    "print(simple_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259995c0",
   "metadata": {},
   "source": [
    "Simple model, with heteroskedastic robust SE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35decb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heterorob_reg = smf.ols(\"price ~ price_online\", data=bpp).fit(cov_type=\"HC3\")\n",
    "print(simple_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691b358",
   "metadata": {},
   "source": [
    "We can easily add controls in this package, but adding things like fixed effects requires using different packages. \n",
    "\n",
    "You will have to do some searching to figure out what works best for your needs!\n",
    "\n",
    "This is not an econometrics class so we will not go any further into regressions for now, but there are great resources available if you want to do regression analysis in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiv_reg = smf.ols(\"price ~ price_online + year\", data=bpp).fit()\n",
    "print(multiv_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20982530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UCA DS Base)",
   "language": "python",
   "name": "ucads_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "02379600d2c1f831ab2aaa73197210a962cfb04f271ff099e74c1844ff770bad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
