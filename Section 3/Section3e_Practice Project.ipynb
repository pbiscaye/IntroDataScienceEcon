{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3d. Practice Project\n",
    "\n",
    "#### Instructor: Pierre Biscaye\n",
    "\n",
    "The content of this notebook draws on material from UC Berkeley's D-Lab Python Fundamentals [course](https://github.com/dlab-berkeley/Python-Fundamentals).\n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Apply the skills you have learned so far to working with a health dataset.\n",
    "* Understand how to navigate file structures in Jupyter.\n",
    "* Apply Pandas methods to concatenate dataframes, clean up data, count and group values, and visualize correlations. \n",
    "* Use your search engine to look up how functions and methods work.\n",
    "\n",
    "### Sections\n",
    "1. Step 1: Import the Data.\n",
    "2. Step 2: Data Cleaning\n",
    "3. Step 3: Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='project'></a>\n",
    "\n",
    "# Step 1: Importing Data \n",
    "\n",
    "### Data: California Health Interview Survey\n",
    "The [California Health Interview Survey (CHIS)](https://healthpolicy.ucla.edu/chis/Pages/default.aspx) is the United States's largest state health survey and a critical source of data on Californians as well as on the state's various racial and ethnic groups. The data has been altered for demonstration purposes.\n",
    "\n",
    "The dataset has the following columns:\n",
    "\n",
    "- `general_health`: Self-Reported assessment of general health\n",
    "- `veg_perweek`: How many vegetables consumed per week\n",
    "- `feel_left_out`: How often feeling left out\n",
    "- `poverty_level`: Poverty level as Times of 100% Federal Poverty Line (FPL)\n",
    "- `household_tenure`: Self-Reported household tenure\n",
    "- `interview_language`: Language of interview\n",
    "\n",
    "For this project, the goal we want to accomplish is **visualizing the relationship between poverty level and general health**. We will bring together basic programming and data science techniques you have learned to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filepaths\n",
    "\n",
    "Before we import our data, a few words on **filepaths**. \n",
    "\n",
    "A filepath is the location of a file on your system. There are two kinds of filepaths:\n",
    "\n",
    "* **absolute**: The filepath from the top level folder of your system.\n",
    "* **relative**: The filepath relative to the current working directory (i.e. this notebook's location).\n",
    "\n",
    "When you are figuring out what filepath to use, you can use `os.listdir([PATH])` to list all subdirectories in a path. For example, let's see what directories are available to us in the current folder (noted with a dot `.`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up the items in the folder after moving up one level works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter Lab's File Browser (the folder icon in top left of your screen),  you can navigate to a folder, right-click on a file and select `Copy Path` to get the absolute filepath of a file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading in the Data\n",
    "\n",
    "Locate the files in the \"chis_data\" folder, which is in the \"Section 3\" folder. Using `pd.read_csv()`, read in all three data frames and assign them to the three variables defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatenating DataFrames\n",
    "\n",
    "Use a function to **concatenate** the three DataFrames we have now. If may be useful to first inspect the 3 dataframes using the `head()` method to think about how you should concatenate them. \n",
    "\n",
    "Save the concatenated list in a new variable called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the final data frame.\n",
    "\n",
    "1. How many rows and columns are there in the concatenated DataFrame?\n",
    "2. How many numeric columns are there in the dataset?\n",
    "3. What data type are the values in the `poverty_level` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reset the index\n",
    "df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "\n",
    "# Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we will want to remove some missing values in a DataFrame. Have a look at the `general_health` column and find the missing values using the `.isna()` method. Then, use `.sum()` to sum the amount of undefined (NaN) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the non-existent values in this column with the `.dropna()` method. Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) to see how to do this. Save the new datset dropping those rows with missing values as `df`.\n",
    "\n",
    "**Tip**: Use the `subset` argument to select a specific column to remove values from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Basic Data Analysis\n",
    "\n",
    "Now that we have preprocessed data, we want to analyze it. Recall that our goal is to visualize a relationship between poverty level and general health. Before we do this, we should get a better grasp of what is in our data.\n",
    "\n",
    "## Counting Values\n",
    "The first thing we will want to do is count values of poverty levels: we want to see how many levels there are, and how the data are distributed. First, run `value_counts()` on the `poverty_level` column. \n",
    "\n",
    "Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) for `value_counts()`. What parameter can you use to normalize the output (i.e., to get proportions of observations)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating a Function\n",
    "\n",
    "It turns out that poverty is expressed \"as Times of 100% Federal Poverty Line (FPL)\".\n",
    "For instance, `\"100-199%\" FPL\"` means that the row's income was 1-1.99 times the FPL.\n",
    "One approach to this statistic could be to see if we can find differences in general health for people **below and above the poverty line**. \n",
    "\n",
    "To do this, we can create a function that takes in values of the `poverty_level` column and outputs whether that value is above or below the poverty line.\n",
    "\n",
    "1. Create a new function called `assign_level`. It takes one parameter, which we'll call `i`.\n",
    "2. If `i` is `\"0-99% FPL\"`, return 0. In all other cases, return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Define the assign_level function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Function\n",
    "\n",
    "We can use the `apply()` method in Pandas to apply our new function to the `poverty_level` column of our DataFrame. We also want to save the output of this `apply()` method to a new column in our DataFrame. \n",
    "\n",
    "1. Use the `apply()` method on the `poverty_level` column. Pass your `assign_level` function as the argument.\n",
    "2. Save the result of this operation in a new column in your `df`, called `above_fpl`.\n",
    "3. Test that you did this right by taking the mean of `above_fpl` and comparing it to the normalized value counts you generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Apply the function to the poverty_level column and create a new column\n",
    "\n",
    "# Check the mean to compare against the proportions you found above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting a DataFrame\n",
    "\n",
    "In order to create two bar plots of general health – for people above and below the poverty line – we can create two DataFrames for just these groups. We can then plot the values in these DataFrames \"on top of\" one another in a barplot.\n",
    "\n",
    "Recall that we can subset DataFrames with Boolean masks. For instance, say we have a DataFrame `counts` with a column `A`. If we want to create a new DataFrame called `above_800`, which only contains the values over 800 in column `A` of `counts`, we would write:\n",
    "\n",
    "```\n",
    "above_800 = counts[counts['A'] > 800]\n",
    "```\n",
    "\n",
    "Let's perform the same operation on our data.\n",
    "\n",
    "1. Create a new DataFrame, `df_below`. It will be a subset of our `df`, based on the condition that the value in `above_poverty_line` is 0.\n",
    "2. Create a new DataFrame, `df_above`. It will be a subset of our `df`, based on the condition that the value in `above_poverty_line` is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Visualization\n",
    "\n",
    "Finally, let's create our bar plots. We will create 2 plots in 1 cell, which will be plotted on top of one another. \n",
    "\n",
    "Fill in the blanks below, following the steps. \n",
    "\n",
    "1. Run a **normalized** `value_counts()` on the `general_health` column of `df_above` and `df_below`.\n",
    "2. Run `plot()` on the output of the resulting DataFrames. Enter the values for two arguments: `kind` is the type of plot, and `alpha` is a measure of transparency between 0 and 1 to allow you to see both results. Specify different colors for the two bars. Add labels for each, and insert a legend in the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Key Points\n",
    "\n",
    "* File structures can be navigated using absolute and relative file paths.\n",
    "* The `.dropna()` method in Pandas removes missing values from a `DataFrame` or `Series`.\n",
    "* Custom Functions can be applied to the axis of a DataFrame using `apply()`.\n",
    "* Subsetting DataFrames based on some condition can help with creating comparative visualizations.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
